{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lavie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import albumentations as A # 데이터 증식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5), # 좌우 반전\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5), # 밝기 및 대비 조절\n",
    "    A.ShiftScaleRotate(p=0.5), # 이동, 확대/축소, 회전\n",
    "])\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Clean 폴더 이미지 불러오기\n",
    "clean_dir = 'Data_PlasticCup/clean'\n",
    "for filename in os.listdir(clean_dir):\n",
    "    img = cv2.imread(os.path.join(clean_dir, filename))\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    augmented = transform(image=img)\n",
    "    augmented_img = augmented['image']\n",
    "    data.append(augmented_img)\n",
    "    labels.append(0)  # 0 = 깨끗한 컵\n",
    "\n",
    "# NG 폴더 이미지 불러오기\n",
    "ng_dir = 'Data_PlasticCup/ng'\n",
    "for filename in os.listdir(ng_dir):\n",
    "    img = cv2.imread(os.path.join(ng_dir, filename))\n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    augmented = transform(image=img)\n",
    "    augmented_img = augmented['image']\n",
    "    data.append(augmented_img)\n",
    "    labels.append(1)  # 1 = 더러운 컵\n",
    "\n",
    "# 데이터 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(data, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 [==============================] - ETA: 0s - loss: 23.1981 - accuracy: 0.6930WARNING:tensorflow:5 out of the last 160 calls to <function Model.make_test_function.<locals>.test_function at 0x000001606BF29D00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "10/10 [==============================] - 2s 111ms/step - loss: 23.1981 - accuracy: 0.6930 - val_loss: 0.1950 - val_accuracy: 0.9494\n",
      "Epoch 2/30\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.2923 - accuracy: 0.8924 - val_loss: 0.2189 - val_accuracy: 0.9241\n",
      "Epoch 3/30\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.1972 - accuracy: 0.9304 - val_loss: 0.2302 - val_accuracy: 0.9114\n",
      "Epoch 4/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.1052 - accuracy: 0.9557 - val_loss: 0.3068 - val_accuracy: 0.8861\n",
      "Epoch 5/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.0832 - accuracy: 0.9715 - val_loss: 0.2484 - val_accuracy: 0.9747\n",
      "Epoch 6/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 0.2353 - val_accuracy: 0.9747\n",
      "Epoch 7/30\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.0600 - accuracy: 0.9778 - val_loss: 0.3410 - val_accuracy: 0.9747\n",
      "Epoch 8/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.0581 - accuracy: 0.9747 - val_loss: 0.2696 - val_accuracy: 0.9873\n",
      "Epoch 9/30\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.3195 - val_accuracy: 0.9747\n",
      "Epoch 10/30\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.0231 - accuracy: 0.9937 - val_loss: 0.3027 - val_accuracy: 0.9747\n",
      "Epoch 11/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.0300 - accuracy: 0.9905 - val_loss: 0.4022 - val_accuracy: 0.9873\n",
      "Epoch 12/30\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.5256 - val_accuracy: 0.9873\n",
      "Epoch 13/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.4797 - val_accuracy: 0.9873\n",
      "Epoch 14/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.4275 - accuracy: 0.9684 - val_loss: 0.3874 - val_accuracy: 0.9620\n",
      "Epoch 15/30\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.1981 - accuracy: 0.9715 - val_loss: 0.8475 - val_accuracy: 0.7722\n",
      "Epoch 16/30\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.1464 - accuracy: 0.9462 - val_loss: 0.3666 - val_accuracy: 0.9747\n",
      "Epoch 17/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.1764 - accuracy: 0.9209 - val_loss: 0.3827 - val_accuracy: 0.9494\n",
      "Epoch 18/30\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.1470 - accuracy: 0.9525 - val_loss: 0.5470 - val_accuracy: 0.9747\n",
      "Epoch 19/30\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 0.0959 - accuracy: 0.9810 - val_loss: 0.6530 - val_accuracy: 0.9620\n",
      "Epoch 20/30\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.2086 - accuracy: 0.9399 - val_loss: 0.5253 - val_accuracy: 0.9494\n",
      "Epoch 21/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.0285 - accuracy: 0.9873 - val_loss: 0.8442 - val_accuracy: 0.9241\n",
      "Epoch 22/30\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.0468 - accuracy: 0.9842 - val_loss: 0.4069 - val_accuracy: 0.9747\n",
      "Epoch 23/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.0215 - accuracy: 0.9905 - val_loss: 0.3867 - val_accuracy: 0.9873\n",
      "Epoch 24/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.0308 - accuracy: 0.9937 - val_loss: 0.4928 - val_accuracy: 0.9747\n",
      "Epoch 25/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.0124 - accuracy: 0.9968 - val_loss: 0.4933 - val_accuracy: 0.9873\n",
      "Epoch 26/30\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.0494 - accuracy: 0.9905 - val_loss: 0.6084 - val_accuracy: 0.9747\n",
      "Epoch 27/30\n",
      "10/10 [==============================] - 1s 87ms/step - loss: 0.0238 - accuracy: 0.9968 - val_loss: 0.5274 - val_accuracy: 0.9873\n",
      "Epoch 28/30\n",
      "10/10 [==============================] - 1s 89ms/step - loss: 0.0369 - accuracy: 0.9937 - val_loss: 0.5711 - val_accuracy: 0.9747\n",
      "Epoch 29/30\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.0269 - accuracy: 0.9873 - val_loss: 0.6506 - val_accuracy: 0.9747\n",
      "Epoch 30/30\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 0.1145 - accuracy: 0.9778 - val_loss: 1.0124 - val_accuracy: 0.9747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lavie\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "model = Sequential()\n",
    "\n",
    "# 컨볼루션 레이어 1\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# 컨볼루션 레이어 2 \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# 컨볼루션 레이어 3\n",
    "model.add(Conv2D(128, (3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# fully connected 레이어\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 데이터를 NumPy 배열로 변환\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_val = np.array(x_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=30, batch_size=32)\n",
    "\n",
    "# 모델 저장\n",
    "model.save('plastic_cup_classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 1.0124 - accuracy: 0.9747 - 268ms/epoch - 89ms/step\n",
      "Test accuracy: 97.47%\n",
      "3/3 [==============================] - 0s 30ms/step\n",
      "Accuracy (using sklearn.metrics): 97.47%\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('plastic_cup_classifier.h5')\n",
    "\n",
    "# 테스트 데이터셋 준비\n",
    "x_test = np.array(x_val)\n",
    "y_test = np.array(y_val)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')\n",
    "\n",
    "# 예측값 구하기\n",
    "y_pred = (model.predict(x_test) > 0.5).astype(int)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy (using sklearn.metrics): {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
